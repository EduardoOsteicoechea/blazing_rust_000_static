name: Deploy Static Files to EC2

on:
  push:
    branches: [ "main" ] # This workflow triggers on pushes to the 'main' branch.

jobs:
  deploy:
    runs-on: ubuntu-latest # The job will run on a fresh Ubuntu runner provided by GitHub Actions.
    steps:
      - name: Checkout code
        uses: actions/checkout@v3 # Checks out your repository code into the runner.

      - name: Set up AWS credentials
        uses: aws-actions/configure-aws-credentials@v1 # Configures AWS credentials for interacting with AWS services.
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} # Your AWS Access Key ID, stored as a GitHub secret.
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }} # Your AWS Secret Access Key, stored as a GitHub secret.
          aws-region: ${{ secrets.AWS_REGION }} # Your AWS region, stored as a GitHub secret.

      - name: Prepare and Archive Flattened Static Files on Runner
        id: prepare_archive # Assign an ID to this step to reference its outputs later.
        run: |
          # Create a temporary directory on the runner to collect all static files in a flat structure.
          FLAT_STATIC_DIR=$(mktemp -d)
          echo "Created temporary directory for flattened files on runner: $FLAT_STATIC_DIR"

          # Find all .css and .js files in the entire repository (checked out in current directory)
          # and copy them directly into the FLAT_STATIC_DIR.
          # The -L option for cp ensures symbolic links are followed.
          # If files with the same name exist in different original subdirectories, the last one found will overwrite previous ones.
          find . -type f \( -name "*.css" -o -name "*.js" \) -exec cp -L {} "$FLAT_STATIC_DIR" \;
          
          echo "Files copied to temporary directory:"
          ls -l "$FLAT_STATIC_DIR" # List the files to verify they are flat.

          # Create a tar.gz archive of the *contents* of the flattened directory.
          # We navigate into the FLAT_STATIC_DIR, then tar its contents.
          ARCHIVE_NAME="static_files_bundle.tar.gz"
          cd "$FLAT_STATIC_DIR"
          tar -czvf "../../$ARCHIVE_NAME" . # Create archive one level up from FLAT_STATIC_DIR
          cd - # Go back to original directory

          echo "Created archive: $ARCHIVE_NAME"
          
          # Make the path of the archive available as an output for the next step.
          echo "archive_path=$ARCHIVE_NAME" >> $GITHUB_OUTPUT

      - name: Ensure /var/www/html directory exists and is writable on EC2
        uses: appleboy/ssh-action@master # Use SSH action to run commands on EC2.
        with:
          host: ${{ secrets.HOST_DNS }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            echo "Ensuring /var/www/html exists and has correct permissions..."
            # Create the directory if it doesn't exist. -p means no error if it exists.
            sudo mkdir -p /var/www/html
            # Change ownership to your SSH user so it has write permissions.
            # Replace ${{ secrets.USERNAME }} with your actual SSH username (e.g., 'ubuntu').
            sudo chown -R ${{ secrets.USERNAME }}:${{ secrets.USERNAME }} /var/www/html
            # Set appropriate permissions for web content (read/execute for others, full for owner).
            sudo chmod -R 755 /var/www/html
            # Clean up existing CSS/JS files in /var/www/html to ensure a fresh deployment,
            # ensuring no old files persist that aren't in the new deployment.
            echo "Cleaning up existing .css and .js files in /var/www/html..."
            sudo find /var/www/html/ -maxdepth 1 -type f \( -name "*.css" -o -name "*.js" \) -delete

      - name: Copy Static Files Archive to EC2
        uses: appleboy/scp-action@master # Uses SCP action to securely copy the prepared archive.
        with:
          host: ${{ secrets.HOST_DNS }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          source: "${{ steps.prepare_archive.outputs.archive_path }}" # Path to the tar.gz archive on the runner.
          target: "/tmp/" # Temporary destination directory on EC2.
          overwrite: true # Overwrite the archive if it exists.

      - name: Extract Files and Cleanup on EC2, Restart Nginx
        uses: appleboy/ssh-action@master # Use SSH action to perform final operations on EC2.
        with:
          host: ${{ secrets.HOST_DNS }}
          username: ${{ secrets.USERNAME }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            ARCHIVE_NAME=$(basename "${{ steps.prepare_archive.outputs.archive_path }}")
            REMOTE_ARCHIVE_PATH="/tmp/$ARCHIVE_NAME"

            echo "Extracting $REMOTE_ARCHIVE_PATH to /var/www/html..."
            # Extract the archive directly into /var/www/html.
            # -C /var/www/html changes the directory before extracting.
            sudo tar -xzvf "$REMOTE_ARCHIVE_PATH" -C /var/www/html/

            echo "Removing temporary archive $REMOTE_ARCHIVE_PATH..."
            sudo rm -f "$REMOTE_ARCHIVE_PATH" # Remove the archive file.

            echo "Clearing Nginx cache..."
            sudo rm -rf /var/cache/nginx/*

            echo "Restarting Nginx..."
            sudo systemctl restart nginx
            echo "Reloading Nginx configuration..."
            sudo systemctl reload nginx 

      - name: Wait for deployment
        run: |
          echo "Waiting 10 seconds for Nginx to settle..."
          sleep 10